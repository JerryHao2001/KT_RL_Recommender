{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from sb3_contrib import TRPO\n",
    "import pickle\n",
    "from akt import AKT\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PracticeProblemEnv(gym.Env):\n",
    "    def __init__(self, params, max_step=10, rew_func=\"mock\", n_PperQ = 1, units=None, device=\"cuda\"):\n",
    "        super(PracticeProblemEnv, self).__init__()\n",
    "        self.max_step = max_step\n",
    "        self.rew_func = rew_func\n",
    "        self.n_PperQ = n_PperQ if (self.rew_func == \"mock\") else None\n",
    "\n",
    "        self.params = params\n",
    "        self.device = device\n",
    "        self.kt_model = self._load_model()\n",
    "        self.p_q_dict, self.q_p_dict = self._load_pq_qp_dict(units)\n",
    "\n",
    "        self.actions = [*self.p_q_dict.keys()]\n",
    "        self.action_space = gym.spaces.Discrete(len(self.actions)) #[0,n_question-1]\n",
    "        self.observation_space = gym.spaces.Box(np.array([1,0,1]), np.array([self.params.n_question, 1, self.params.n_pid])) #[1,n_question]/[0,1]/[1,n_pid]\n",
    "   \n",
    "\n",
    "\n",
    "        self.reset()\n",
    "    \n",
    "    def _load_model(self, pretrained_path=\"_b24_nb1_gn-1_lr1e-05_s224_sl200_do0.05_dm256_ts1_kq1_l21e-05_178\"):\n",
    "        model = AKT(n_question=self.params.n_question, n_pid=self.params.n_pid, n_blocks=self.params.n_block, d_model=self.params.d_model,\n",
    "                    dropout=self.params.dropout, kq_same=self.params.kq_same, model_type='akt', l2=self.params.l2).to(self.device)\n",
    "        checkpoint = torch.load(os.path.join( 'model', self.params.model, self.params.save, pretrained_path))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        self.history = {'q':[],'target':[],'pid':[]} # Initialize past interactions\n",
    "        self.curr_step = 0\n",
    "        self.curr_q = -1\n",
    "        self.curr_pred = -1\n",
    "        self.curr_pid = -1\n",
    "\n",
    "        return self.step(self.action_space.sample())[0], {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([self.curr_q, self.curr_pred, self.curr_pid], dtype=int)\n",
    "        \n",
    "    def _rew(self, n_PperQ=1):\n",
    "        sampled_concpets = []\n",
    "        sampled_problems = []\n",
    "        for question_type, question_ids in self.q_p_dict.items():\n",
    "            num = min(n_PperQ, len(question_ids))\n",
    "            sampled_problems += random.sample([*question_ids], num)\n",
    "            sampled_concpets += ([question_type ] * num)\n",
    "\n",
    "        mean_performance = self.predict(sampled_concpets,sampled_problems)\n",
    "        return mean_performance\n",
    "    \n",
    "    def switch_rew(self, new_rew_func):\n",
    "        self.rew_func = new_rew_func\n",
    "    \n",
    "    def step(self, action):#action is an np int e.g. nparray(3) of the index of the action specified in self.actions\n",
    "        self.curr_step += 1\n",
    "        self.curr_pid = self.actions[action]\n",
    "        self.curr_q = self.p_q_dict[self.curr_pid]\n",
    "\n",
    "        correct_prob = self.predict([self.curr_q],[self.curr_pid])\n",
    "        # correct_prob = self.predict()\n",
    "        self.curr_pred = np.random.rand() < correct_prob\n",
    "\n",
    "        # Update history with the action and the correctness\n",
    "        self.history['q'] += [self.curr_q]\n",
    "        self.history['target'] += [self.curr_pred]\n",
    "        self.history['pid'] += [self.curr_pid]\n",
    "\n",
    "        if self.rew_func == \"mock\":\n",
    "            reward = self._rew(n_PperQ=self.n_PperQ)\n",
    "        elif self.rew_func == \"correct\":\n",
    "            reward = 1 if self.curr_pred else 0\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        # Recompute the state using the kt_model for each question\n",
    "        obs = self._get_obs()\n",
    "\n",
    "        done = self.curr_step >= self.max_step\n",
    "        good = (self.rew_func == \"mock\") and (reward > 0.9)\n",
    "\n",
    "        return obs, reward, done, good, {}\n",
    "    \n",
    "    def predict(self, curr_q, curr_pid):\n",
    "\n",
    "        batch_size = len(curr_q)\n",
    "\n",
    "        q = torch.cat((torch.tensor(self.history['q'][-(self.params.seqlen-1):]).tile((batch_size,1)),(torch.tensor(curr_q).unsqueeze(-1))),1)\n",
    "        target = torch.tensor(self.history['target'][-(self.params.seqlen-1):]+[0]).tile((batch_size,1))\n",
    "        pid = torch.cat((torch.tensor(self.history['pid'][-(self.params.seqlen-1):]).tile((batch_size,1)),(torch.tensor(curr_pid).unsqueeze(-1))),1)\n",
    "        assert pid.shape == target.shape == pid.shape #(test_n_problem,3)\n",
    "        qa = q+target*self.params.n_question\n",
    "        \n",
    "        padded_q = torch.zeros((batch_size, self.params.seqlen))\n",
    "        padded_qa = torch.zeros((batch_size, self.params.seqlen))\n",
    "        padded_target = torch.full((batch_size,self.params.seqlen),-1)\n",
    "        padded_pid = torch.zeros((batch_size, self.params.seqlen))\n",
    "\n",
    "        pred_index = q.shape[1]\n",
    "        padded_q[:, :pred_index]= q\n",
    "        padded_qa[:, :pred_index]= qa\n",
    "        padded_target[:, :pred_index]= target\n",
    "        padded_pid[:, :pred_index]= pid\n",
    "\n",
    "        q = padded_q.long().to(device)\n",
    "        qa = padded_qa.long().to(device)\n",
    "        target = padded_target.long().to(device)\n",
    "        pid = padded_pid.long().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss, pred, ct = self.kt_model(q,qa,target,pid)\n",
    "\n",
    "        nopadding_index = np.flatnonzero(padded_target.reshape((-1,)) >= -0.9).tolist()\n",
    "        pred_nopadding = pred[nopadding_index]\n",
    "\n",
    "        test_result = pred_nopadding[(pred_index-1)::pred_index]\n",
    "        assert test_result.shape == (batch_size,)\n",
    "        correct_prob = test_result.mean().item()\n",
    "\n",
    "        return correct_prob\n",
    "\n",
    "    def _load_pq_qp_dict(self, units=None):\n",
    "        def iterate_over_data(file_path):\n",
    "            with open(file_path, mode='r') as file:\n",
    "                reader = csv.reader(file)\n",
    "                rows = list(reader)\n",
    "\n",
    "            for i in range(0, len(rows), 4):\n",
    "                # Extract the question ids and concept ids\n",
    "                # question_ids = [int(q) for q in rows[i+1] if q]\n",
    "                # concept_ids = [int(c) for c in rows[i+2] if c]\n",
    "                q_c_ids = [(int(q),int(c)) for (q,c) in zip(rows[i+1],rows[i+2]) if (q and c and ((units is None) or (int(c) in units)))]\n",
    "\n",
    "                # Build the dictionary mapping question ids to concept ids\n",
    "                for question_id, concept_id in q_c_ids:\n",
    "                    if question_id not in p_q_dict:\n",
    "                        p_q_dict[question_id] = concept_id\n",
    "                    if concept_id not in q_p_dict:\n",
    "                        q_p_dict[concept_id] = {question_id}\n",
    "                    else:\n",
    "                        q_p_dict[concept_id].add(question_id)\n",
    "\n",
    "\n",
    "        p_q_file,  q_p_file,  = 'p_q_dict.json', 'q_p_dict.json'\n",
    "        p_q_dict, q_p_dict = {}, {}\n",
    "\n",
    "        # Check if files exist\n",
    "        if os.path.exists(p_q_file) and os.path.exists(q_p_file):\n",
    "            # Load the dictionaries from the files\n",
    "            with open(p_q_file, 'r') as p_q_f:\n",
    "                p_q_dict = json.load(p_q_f)\n",
    "            with open(q_p_file, 'r') as q_p_f:\n",
    "                q_p_dict = json.load(q_p_f)\n",
    "            p_q_dict = {int(k):v for k,v in p_q_dict.items()}\n",
    "            q_p_dict = {int(k):v for k,v in q_p_dict.items()}\n",
    "\n",
    "        else:\n",
    "            all_files = os.listdir(self.params.data_dir)\n",
    "\n",
    "            # Filter the list to include only CSV files\n",
    "            csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "\n",
    "            for f in csv_files:\n",
    "                old_dict = p_q_dict.copy()\n",
    "                iterate_over_data(self.params.data_dir+'/'+ f)\n",
    "                if old_dict == p_q_dict:\n",
    "                    break\n",
    "            \n",
    "            q_p_dict = {k:list(v) for k,v in q_p_dict.items()}\n",
    "\n",
    "            print(q_p_dict.keys())\n",
    "            \n",
    "            with open(p_q_file, 'w') as p_q_f:\n",
    "                json.dump(p_q_dict, p_q_f)\n",
    "            with open(q_p_file, 'w') as q_p_f:\n",
    "                json.dump(q_p_dict, q_p_f)\n",
    "        \n",
    "        return p_q_dict, q_p_dict\n",
    "    \n",
    "    def check_hist(self):\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "with open('result/akt_pid/assist2009_pid/args.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "env = PracticeProblemEnv(params,max_step=100, rew_func='mock', n_PperQ=10, units = [1], device=device)\n",
    "\n",
    "# Define and train the TRPO model\n",
    "model = TRPO('MlpPolicy', env, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.8     |\n",
      "|    ep_rew_mean     | 23.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 48       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 31.9     |\n",
      "|    ep_rew_mean            | 20.4     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 49       |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 82       |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 5.67e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00659  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 1        |\n",
      "|    policy_objective       | 0.0298   |\n",
      "|    value_loss             | 17       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 29.1     |\n",
      "|    ep_rew_mean            | 19.3     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 49       |\n",
      "|    iterations             | 3        |\n",
      "|    time_elapsed           | 125      |\n",
      "|    total_timesteps        | 6144     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | -0.00104 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00639  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 2        |\n",
      "|    policy_objective       | 0.03     |\n",
      "|    value_loss             | 23.6     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 22.3      |\n",
      "|    ep_rew_mean            | 15.3      |\n",
      "| time/                     |           |\n",
      "|    fps                    | 48        |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 168       |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -0.000909 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00651   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 3         |\n",
      "|    policy_objective       | 0.0292    |\n",
      "|    value_loss             | 32.2      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 29.5     |\n",
      "|    ep_rew_mean            | 19.3     |\n",
      "| time/                     |          |\n",
      "|    fps                    | 48       |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 209      |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | -0.00144 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00628  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 4        |\n",
      "|    policy_objective       | 0.0287   |\n",
      "|    value_loss             | 41.2     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.trpo.trpo.TRPO at 0x1cddb0239a0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_1000_100_mock1\")\n",
    "# model.load(\"model_1000_100_mock1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "# model.load(\"model_1000_100_mock1\")\n",
    "\n",
    "obs, _ = env.reset()\n",
    "env.switch_rew(\"correct\")\n",
    "obs_list = []\n",
    "total_rewards = []\n",
    "k=100\n",
    "for _ in range(k):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, terminated, truncated, info = env.step(action)\n",
    "    total_rewards.append(rewards)\n",
    "    obs_list.append(obs)\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "Counter([i[0] for i in obs_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/akt_pid/assist2009_pid/args.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "env = PracticeProblemEnv(params,max_step=1000, rew_func='greedy',device=device)\n",
    "obs, _ = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, rewards, terminated, truncated, info = env.step(np.array(75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.q_p_dict\n",
    "sampled_concpets = []\n",
    "sampled_problems = []\n",
    "n_problems_per_type = 10\n",
    "for question_type, question_ids in env.q_p_dict.items():\n",
    "    num = min(n_problems_per_type, len(question_ids))\n",
    "    sampled_problems += random.sample([*question_ids], num)\n",
    "    sampled_concpets += ([question_type ] * num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_problems = sampled_problems[:1]\n",
    "# sampled_concpets = sampled_concpets[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_problem = len(sampled_problems)\n",
    "q = torch.cat((torch.tensor(env.history['q'][-(env.params.seqlen-1):]).tile((test_n_problem,1)),(torch.tensor(sampled_concpets).unsqueeze(-1))),1)\n",
    "target = torch.tensor(env.history['target'][-(env.params.seqlen-1):]+[0]).tile((test_n_problem,1))\n",
    "pid = torch.cat((torch.tensor(env.history['pid'][-(env.params.seqlen-1):]).tile((test_n_problem,1)),(torch.tensor(sampled_problems).unsqueeze(-1))),1)\n",
    "assert pid.shape == target.shape == pid.shape #(test_n_problem,3)\n",
    "qa = q+target*env.params.n_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_q = torch.zeros((test_n_problem, env.params.seqlen)) \n",
    "padded_qa = torch.zeros((test_n_problem, env.params.seqlen))\n",
    "padded_target = torch.full((test_n_problem,env.params.seqlen),-1)\n",
    "padded_pid = torch.zeros((test_n_problem, env.params.seqlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = q.shape[1]\n",
    "padded_q[:, :pred_index]= q\n",
    "padded_qa[:, :pred_index]= qa\n",
    "padded_target[:, :pred_index]= target\n",
    "padded_pid[:, :pred_index]= pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = padded_q.long().to(device)\n",
    "qa = padded_qa.long().to(device)\n",
    "target = padded_target.long().to(device)\n",
    "pid = padded_pid.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss, pred, ct = env.kt_model(q,qa,target,pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopadding_index = np.flatnonzero(padded_target.reshape((-1,)) >= -0.9).tolist()\n",
    "pred_nopadding = pred[nopadding_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pred_nopadding[(pred_index-1)::pred_index]\n",
    "assert test_result.shape == (test_n_problem,)\n",
    "mean_performance = test_result.mean().item()\n",
    "# return mean_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
