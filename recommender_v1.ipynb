{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from sb3_contrib import TRPO\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.init import constant_\n",
    "from torch.nn.init import xavier_normal_\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from enum import IntEnum\n",
    "import numpy as np\n",
    "import pickle\n",
    "from akt import AKT\n",
    "import os\n",
    "from load_data import DATA, PID_DATA\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PracticeProblemEnv(gym.Env):\n",
    "    def __init__(self, params, max_step=10, rew_func=\"mock\", device=\"cuda\"):\n",
    "        super(PracticeProblemEnv, self).__init__()\n",
    "        # self.curr_step = None\n",
    "        self.max_step = max_step\n",
    "        self.rew_func = rew_func\n",
    "        # self.curr_q = -1\n",
    "        # self.curr_pred = -1\n",
    "        # self.curr_pid = -1\n",
    "\n",
    "        self.params = params\n",
    "        self.device = device\n",
    "        self.kt_model = self._load_model()\n",
    "        self.p_q_dict = self._load_p_q_dict()\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.params.n_pid,start=1) #[1,n_pid]\n",
    "        self.observation_space = spaces.Box(np.array([1,0,1]), np.array([self.params.n_question, 1, self.params.n_pid])) #[1,n_question]/[0,1]/[1,n_pid]\n",
    "        # self.observation_space = spaces.Tuple([spaces.Discrete(self.params.n_question+1),spaces.Discrete(2),spaces.Discrete(self.params.n_pid+1)])\n",
    "\n",
    "\n",
    "        self.reset()\n",
    "    \n",
    "    def _load_model(self,pretrained_path=\"_b24_nb1_gn-1_lr1e-05_s224_sl200_do0.05_dm256_ts1_kq1_l21e-05_178\"):\n",
    "        model = AKT(n_question=self.params.n_question, n_pid=self.params.n_pid, n_blocks=self.params.n_block, d_model=self.params.d_model,\n",
    "                    dropout=self.params.dropout, kq_same=self.params.kq_same, model_type='akt', l2=self.params.l2).to(self.device)\n",
    "        checkpoint = torch.load(os.path.join( 'model', self.params.model, self.params.save, pretrained_path))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        self.history = {'q':[],'target':[],'pid':[]} # Initialize past interactions\n",
    "        self.curr_step = 0\n",
    "        self.curr_q = -1\n",
    "        self.curr_pred = -1\n",
    "        self.curr_pid = -1\n",
    "        return self.step(np.random.choice(range(self.params.n_pid)))[0], {}\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([self.curr_q, self.curr_pred, self.curr_pid], dtype=int)\n",
    "        \n",
    "    def _rew(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def step(self, action):#action needs to be a tuple of q and pid like (1,1000)\n",
    "        self.curr_step += 1\n",
    "        self.curr_pid = action.item()\n",
    "        self.curr_q = self.p_q_dict[self.curr_pid]\n",
    "\n",
    "        correct_prob = self.predict()\n",
    "        self.curr_pred = np.random.rand() < correct_prob\n",
    "\n",
    "        if self.rew_func == \"mock\":\n",
    "            reward = self._rew()\n",
    "        elif self.rew_func == \"greedy\":\n",
    "            reward = 1 if self.curr_pred else -1\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        \n",
    "        # Update history with the action and the correctness\n",
    "\n",
    "        self.history['q'] += [self.curr_q]\n",
    "        self.history['target'] += [self.curr_pred]\n",
    "        self.history['pid'] += [self.curr_pid]\n",
    "        \n",
    "        # Recompute the state using the kt_model for each question\n",
    "        # obs = np.array([self.kt_model.predict(self.history + [(i, 0)]) for i in range(self.num_questions)])\n",
    "        obs = self._get_obs()\n",
    "\n",
    "        done = self.curr_step >= self.max_step\n",
    "\n",
    "        return obs, reward, done, done, {}\n",
    "    \n",
    "    def predict(self):\n",
    "        q = np.array(self.history['q'][-(self.params.seqlen-1):]+[self.curr_q])\n",
    "        target = np.array(self.history['target'][-(self.params.seqlen-1):]+[0])\n",
    "        pid = np.array(self.history['pid'][-(self.params.seqlen-1):]+[self.curr_pid])\n",
    "        qa = q+target*self.params.n_question\n",
    "\n",
    "        padded_q = np.zeros((1, self.params.seqlen))\n",
    "        padded_qa = np.zeros((1, self.params.seqlen))\n",
    "        padded_target = np.full((1,self.params.seqlen),-1)\n",
    "        padded_pid = np.zeros((1, self.params.seqlen))\n",
    "\n",
    "        padded_q[0, :len(q)] = q\n",
    "        padded_qa[0, :len(q)] = qa\n",
    "        padded_target[0, :len(target)] = target\n",
    "        padded_pid[0, :len(pid)] = pid\n",
    "\n",
    "        # target_1 = np.floor(target)\n",
    "        q = torch.tensor(padded_q).long().to(self.device)\n",
    "        qa = torch.tensor(padded_qa).long().to(self.device)\n",
    "        target = torch.tensor(padded_target).long().to(self.device)\n",
    "        pid = torch.tensor(padded_pid).long().to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss, pred, ct = self.kt_model(q,qa,target,pid)\n",
    "\n",
    "        nopadding_index = np.flatnonzero(padded_target.reshape((-1,)) >= -0.9).tolist()\n",
    "        pred_nopadding = pred[nopadding_index]\n",
    "        correct_prob = pred_nopadding[-1].item()\n",
    "        return correct_prob\n",
    "\n",
    "    def _load_p_q_dict(self):\n",
    "        def iterate_over_data(file_path):\n",
    "            with open(file_path, mode='r') as file:\n",
    "                reader = csv.reader(file)\n",
    "                rows = list(reader)\n",
    "\n",
    "                # Iterate over the rows in groups of 4\n",
    "                for i in range(0, len(rows), 4):\n",
    "                    # Extract the question ids and concept ids\n",
    "                    question_ids = [int(q) for q in rows[i+1] if q]\n",
    "                    concept_ids = [int(c) for c in rows[i+2] if c]\n",
    "                    \n",
    "                    # Build the dictionary mapping question ids to concept ids\n",
    "                    for question_id, concept_id in zip(question_ids, concept_ids):\n",
    "                        if question_id not in question_concept_dict:\n",
    "                            question_concept_dict[question_id] = concept_id\n",
    "\n",
    "        all_files = os.listdir(self.params.data_dir)\n",
    "\n",
    "        # Filter the list to include only CSV files\n",
    "        csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "        question_concept_dict = {}\n",
    "        for f in csv_files:\n",
    "            old_dict = question_concept_dict.copy()\n",
    "            iterate_over_data(self.params.data_dir+'/'+ f)\n",
    "            if old_dict == question_concept_dict:\n",
    "                break\n",
    "        \n",
    "        return question_concept_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 999      |\n",
      "|    ep_rew_mean     | -363     |\n",
      "| time/              |          |\n",
      "|    fps             | 92       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.trpo.trpo.TRPO at 0x182412d3700>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open('result/akt_pid/assist2009_pid/args.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "env = PracticeProblemEnv(params,max_step=1000, rew_func='greedy',device=device)\n",
    "\n",
    "# Define and train the TRPO model\n",
    "model = TRPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_1000_1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "obs, _ = env.reset()\n",
    "obs_list = []\n",
    "for _ in range(100):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, terminated, truncated, info = env.step(action)\n",
    "    obs_list.append(obs)\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81, 70, 44, 70, 2, 84, 101, 87, 51, 21, 30, 87, 99, 52, 30, 97, 87, 87, 55, 46, 53, 87, 10, 51, 22, 34, 89, 88, 55, 30, 68, 103, 2, 70, 52, 21, 69, 92, 55, 78, 7, 39, 30, 93, 54, 48, 19, 13, 48, 10, 48, 67, 42, 30, 5, 67, 89, 78, 7, 52, 87, 87, 14, 21, 88, 42, 48, 86, 56, 25, 68, 47, 87, 107, 93, 26, 2, 107, 34, 44, 56, 46, 33, 55, 38, 93, 48, 58, 26, 81, 70, 7, 68, 82, 4, 47, 71, 70, 68, 50]\n",
      "[13447, 12057, 8156, 12166, 220, 13632, 16229, 14588, 9836, 4041, 5814, 14541, 16072, 9849, 5479, 16011, 14339, 14122, 10309, 6779, 9976, 14838, 2263, 9826, 4149, 7000, 15610, 15534, 10375, 5632, 11500, 16306, 223, 11867, 9930, 4019, 11774, 15760, 10340, 13108, 1485, 7654, 5609, 15824, 10978, 9086, 3610, 2575, 8998, 2227, 8939, 11307, 7991, 5904, 977, 11253, 15609, 13099, 1783, 9905, 14250, 14517, 2470, 4042, 15452, 7870, 9143, 13960, 8406, 4423, 11385, 8808, 14967, 16526, 15804, 4627, 184, 16647, 6969, 147, 10725, 8557, 6645, 10449, 7497, 10708, 9378, 11007, 4798, 13418, 12042, 1701, 11455, 13525, 760, 8868, 12334, 12022, 11612, 9519]\n"
     ]
    }
   ],
   "source": [
    "print([i[0] for i in obs_list])\n",
    "print([i[2] for i in obs_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({87: 8,\n",
       "         70: 5,\n",
       "         30: 5,\n",
       "         48: 5,\n",
       "         55: 4,\n",
       "         68: 4,\n",
       "         2: 3,\n",
       "         21: 3,\n",
       "         52: 3,\n",
       "         7: 3,\n",
       "         93: 3,\n",
       "         81: 2,\n",
       "         44: 2,\n",
       "         51: 2,\n",
       "         46: 2,\n",
       "         10: 2,\n",
       "         34: 2,\n",
       "         89: 2,\n",
       "         88: 2,\n",
       "         78: 2,\n",
       "         67: 2,\n",
       "         42: 2,\n",
       "         56: 2,\n",
       "         47: 2,\n",
       "         107: 2,\n",
       "         26: 2,\n",
       "         84: 1,\n",
       "         101: 1,\n",
       "         99: 1,\n",
       "         97: 1,\n",
       "         53: 1,\n",
       "         22: 1,\n",
       "         103: 1,\n",
       "         69: 1,\n",
       "         92: 1,\n",
       "         39: 1,\n",
       "         54: 1,\n",
       "         19: 1,\n",
       "         13: 1,\n",
       "         5: 1,\n",
       "         14: 1,\n",
       "         86: 1,\n",
       "         25: 1,\n",
       "         33: 1,\n",
       "         38: 1,\n",
       "         58: 1,\n",
       "         82: 1,\n",
       "         4: 1,\n",
       "         71: 1,\n",
       "         50: 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "Counter([i[0] for i in obs_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k= 25\n",
    "[i for i in range(50,0,-1)][-k:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
