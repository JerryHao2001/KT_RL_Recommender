{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from sb3_contrib import TRPO\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.init import constant_\n",
    "from torch.nn.init import xavier_normal_\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from enum import IntEnum\n",
    "import numpy as np\n",
    "import pickle\n",
    "from akt import AKT\n",
    "import os\n",
    "from load_data import DATA, PID_DATA\n",
    "import csv\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PracticeProblemEnv(gym.Env):\n",
    "    def __init__(self, params, max_step=10, rew_func=\"mock\", device=\"cuda\"):\n",
    "        super(PracticeProblemEnv, self).__init__()\n",
    "        # self.curr_step = None\n",
    "        self.max_step = max_step\n",
    "        self.rew_func = rew_func\n",
    "        # self.curr_q = -1\n",
    "        # self.curr_pred = -1\n",
    "        # self.curr_pid = -1\n",
    "\n",
    "        self.params = params\n",
    "        self.device = device\n",
    "        self.kt_model = self._load_model()\n",
    "        self.p_q_dict, self.q_p_dict = self._load_pq_qp_dict()\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.params.n_pid,start=1) #[1,n_pid]\n",
    "        self.observation_space = spaces.Box(np.array([1,0,1]), np.array([self.params.n_question, 1, self.params.n_pid])) #[1,n_question]/[0,1]/[1,n_pid]\n",
    "        # self.observation_space = spaces.Tuple([spaces.Discrete(self.params.n_question+1),spaces.Discrete(2),spaces.Discrete(self.params.n_pid+1)])\n",
    "\n",
    "\n",
    "        self.reset()\n",
    "    \n",
    "    def _load_model(self,pretrained_path=\"_b24_nb1_gn-1_lr1e-05_s224_sl200_do0.05_dm256_ts1_kq1_l21e-05_178\"):\n",
    "        model = AKT(n_question=self.params.n_question, n_pid=self.params.n_pid, n_blocks=self.params.n_block, d_model=self.params.d_model,\n",
    "                    dropout=self.params.dropout, kq_same=self.params.kq_same, model_type='akt', l2=self.params.l2).to(self.device)\n",
    "        checkpoint = torch.load(os.path.join( 'model', self.params.model, self.params.save, pretrained_path))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        self.history = {'q':[],'target':[],'pid':[]} # Initialize past interactions\n",
    "        self.curr_step = 0\n",
    "        self.curr_q = -1\n",
    "        self.curr_pred = -1\n",
    "        self.curr_pid = -1\n",
    "        return self.step(np.random.choice(range(1,self.params.n_pid+1)))[0], {}\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([self.curr_q, self.curr_pred, self.curr_pid], dtype=int)\n",
    "        \n",
    "    def _rew(self, n_problems_per_type=1):\n",
    "        sampled_concpets = []\n",
    "        sampled_problems = []\n",
    "        for question_type, question_ids in self.q_p_dict.items():\n",
    "            num = min(n_problems_per_type, len(question_ids))\n",
    "            sampled_problems += random.sample([*question_ids], num)\n",
    "            sampled_concpets += ([question_type ] * num)\n",
    "\n",
    "        mean_performance = self.predict(sampled_concpets,sampled_problems)\n",
    "        return mean_performance\n",
    "    \n",
    "    def switch_rew(self, new_rew_func):\n",
    "        self.rew_func = new_rew_func\n",
    "    \n",
    "    def step(self, action):#action is an np int e.g. nparray(3)\n",
    "        self.curr_step += 1\n",
    "        self.curr_pid = action.item()\n",
    "        self.curr_q = self.p_q_dict[self.curr_pid]\n",
    "\n",
    "        correct_prob = self.predict([self.curr_q],[self.curr_pid])\n",
    "        # correct_prob = self.predict()\n",
    "        self.curr_pred = np.random.rand() < correct_prob\n",
    "\n",
    "        if self.rew_func == \"mock\":\n",
    "            reward = self._rew()\n",
    "        elif self.rew_func == \"correct\":\n",
    "            reward = 1 if self.curr_pred else 0\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        # Update history with the action and the correctness\n",
    "        self.history['q'] += [self.curr_q]\n",
    "        self.history['target'] += [self.curr_pred]\n",
    "        self.history['pid'] += [self.curr_pid]\n",
    "        \n",
    "        # Recompute the state using the kt_model for each question\n",
    "        obs = self._get_obs()\n",
    "\n",
    "        done = self.curr_step >= self.max_step\n",
    "        good = (self.rew_func == \"mock\") and (reward > 0.9)\n",
    "\n",
    "        return obs, reward, done, good, {}\n",
    "    \n",
    "    # def predict(self):\n",
    "    #     q = torch.tensor(self.history['q'][-(self.params.seqlen-1):]+[self.curr_q])\n",
    "    #     target = torch.tensor(self.history['target'][-(self.params.seqlen-1):]+[0])\n",
    "    #     pid = torch.tensor(self.history['pid'][-(self.params.seqlen-1):]+[self.curr_pid])\n",
    "    #     qa = q+target*self.params.n_question\n",
    "\n",
    "    #     padded_q = torch.zeros((1, self.params.seqlen))\n",
    "    #     padded_qa = torch.zeros((1, self.params.seqlen))\n",
    "    #     padded_target = torch.full((1,self.params.seqlen),-1)\n",
    "    #     padded_pid = torch.zeros((1, self.params.seqlen))\n",
    "\n",
    "    #     pred_index = q.shape[0]\n",
    "    #     padded_q[:, :len(q)] = q\n",
    "    #     padded_qa[:, :len(q)] = qa\n",
    "    #     padded_target[:, :len(target)] = target\n",
    "    #     padded_pid[:, :len(pid)] = pid\n",
    "\n",
    "    #     # target_1 = np.floor(target)\n",
    "    #     q = padded_q.long().to(self.device)\n",
    "    #     qa = padded_qa.long().to(self.device)\n",
    "    #     target = padded_target.long().to(self.device)\n",
    "    #     pid = padded_pid.long().to(self.device)\n",
    "        \n",
    "    #     with torch.no_grad():\n",
    "    #         loss, pred, ct = self.kt_model(q,qa,target,pid)\n",
    "\n",
    "    #     nopadding_index = np.flatnonzero(padded_target.reshape((-1,)) >= -0.9).tolist()\n",
    "    #     pred_nopadding = pred[nopadding_index]\n",
    "    #     correct_prob = pred_nopadding[-1].item()\n",
    "    #     return correct_prob\n",
    "    \n",
    "    def predict(self, curr_q, curr_pid):\n",
    "\n",
    "        assert type(curr_q) == type(curr_pid) == list\n",
    "        batch_size = len(curr_q)\n",
    "\n",
    "        q = torch.cat((torch.tensor(self.history['q'][-(self.params.seqlen-1):]).tile((batch_size,1)),(torch.tensor(curr_q).unsqueeze(-1))),1)\n",
    "        target = torch.tensor(self.history['target'][-(self.params.seqlen-1):]+[0]).tile((batch_size,1))\n",
    "        pid = torch.cat((torch.tensor(self.history['pid'][-(self.params.seqlen-1):]).tile((batch_size,1)),(torch.tensor(curr_pid).unsqueeze(-1))),1)\n",
    "        assert pid.shape == target.shape == pid.shape #(test_n_problem,3)\n",
    "        qa = q+target*self.params.n_question\n",
    "        \n",
    "        padded_q = torch.zeros((batch_size, self.params.seqlen))\n",
    "        padded_qa = torch.zeros((batch_size, self.params.seqlen))\n",
    "        padded_target = torch.full((batch_size,self.params.seqlen),-1)\n",
    "        padded_pid = torch.zeros((batch_size, self.params.seqlen))\n",
    "\n",
    "        pred_index = q.shape[1]\n",
    "        padded_q[:, :pred_index]= q\n",
    "        padded_qa[:, :pred_index]= qa\n",
    "        padded_target[:, :pred_index]= target\n",
    "        padded_pid[:, :pred_index]= pid\n",
    "\n",
    "        q = padded_q.long().to(device)\n",
    "        qa = padded_qa.long().to(device)\n",
    "        target = padded_target.long().to(device)\n",
    "        pid = padded_pid.long().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss, pred, ct = self.kt_model(q,qa,target,pid)\n",
    "\n",
    "        nopadding_index = np.flatnonzero(padded_target.reshape((-1,)) >= -0.9).tolist()\n",
    "        pred_nopadding = pred[nopadding_index]\n",
    "\n",
    "        test_result = pred_nopadding[(pred_index-1)::pred_index]\n",
    "        assert test_result.shape == (batch_size,)\n",
    "        correct_prob = test_result.mean().item()\n",
    "\n",
    "        return correct_prob\n",
    "\n",
    "    def _load_pq_qp_dict(self):\n",
    "        def iterate_over_data(file_path):\n",
    "            with open(file_path, mode='r') as file:\n",
    "                reader = csv.reader(file)\n",
    "                rows = list(reader)\n",
    "\n",
    "                # Iterate over the rows in groups of 4\n",
    "                for i in range(0, len(rows), 4):\n",
    "                    # Extract the question ids and concept ids\n",
    "                    question_ids = [int(q) for q in rows[i+1] if q]\n",
    "                    concept_ids = [int(c) for c in rows[i+2] if c]\n",
    "                    \n",
    "                    # Build the dictionary mapping question ids to concept ids\n",
    "                    for question_id, concept_id in zip(question_ids, concept_ids):\n",
    "                        if question_id not in question_concept_dict:\n",
    "                            question_concept_dict[question_id] = concept_id\n",
    "                    if concept_id not in concept_question_dict:\n",
    "                        concept_question_dict[concept_id] = {question_id}\n",
    "                    else:\n",
    "                        concept_question_dict[concept_id].add(question_id)\n",
    "\n",
    "        all_files = os.listdir(self.params.data_dir)\n",
    "\n",
    "        # Filter the list to include only CSV files\n",
    "        csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "        question_concept_dict = {}\n",
    "        concept_question_dict = {}\n",
    "        for f in csv_files:\n",
    "            old_dict = question_concept_dict.copy()\n",
    "            iterate_over_data(self.params.data_dir+'/'+ f)\n",
    "            if old_dict == question_concept_dict:\n",
    "                break\n",
    "        \n",
    "        return question_concept_dict, concept_question_dict\n",
    "    \n",
    "    def check_hist(self):\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 999      |\n",
      "|    ep_rew_mean     | 430      |\n",
      "| time/              |          |\n",
      "|    fps             | 9        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 218      |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.trpo.trpo.TRPO at 0x24348a79640>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('result/akt_pid/assist2009_pid/args.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "env = PracticeProblemEnv(params,max_step=1000, rew_func='mock',device=device)\n",
    "\n",
    "# Define and train the TRPO model\n",
    "model = TRPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_1000_100_mock1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "# model.load(\"model_1000_100_mock1\")\n",
    "model.load(\"model_1000_1000\")\n",
    "obs, _ = env.reset()\n",
    "env.switch_rew(\"mock\")\n",
    "obs_list = []\n",
    "total_rewards = []\n",
    "k=1000\n",
    "for _ in range(k):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, terminated, truncated, info = env.step(action)\n",
    "    total_rewards.append(rewards)\n",
    "    obs_list.append(obs)\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i[0] for i in obs_list])\n",
    "print([i[2] for i in obs_list])\n",
    "print(total_rewards/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9127399921417236\n"
     ]
    }
   ],
   "source": [
    "print(total_rewards[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "Counter([i[0] for i in obs_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/akt_pid/assist2009_pid/args.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "env = PracticeProblemEnv(params,max_step=1000, rew_func='greedy',device=device)\n",
    "obs, _ = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, rewards, terminated, truncated, info = env.step(np.array(75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.q_p_dict\n",
    "sampled_concpets = []\n",
    "sampled_problems = []\n",
    "n_problems_per_type = 10\n",
    "for question_type, question_ids in env.q_p_dict.items():\n",
    "    num = min(n_problems_per_type, len(question_ids))\n",
    "    sampled_problems += random.sample([*question_ids], num)\n",
    "    sampled_concpets += ([question_type ] * num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_problems = sampled_problems[:1]\n",
    "# sampled_concpets = sampled_concpets[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_problem = len(sampled_problems)\n",
    "q = torch.cat((torch.tensor(env.history['q'][-(env.params.seqlen-1):]).tile((test_n_problem,1)),(torch.tensor(sampled_concpets).unsqueeze(-1))),1)\n",
    "target = torch.tensor(env.history['target'][-(env.params.seqlen-1):]+[0]).tile((test_n_problem,1))\n",
    "pid = torch.cat((torch.tensor(env.history['pid'][-(env.params.seqlen-1):]).tile((test_n_problem,1)),(torch.tensor(sampled_problems).unsqueeze(-1))),1)\n",
    "assert pid.shape == target.shape == pid.shape #(test_n_problem,3)\n",
    "qa = q+target*env.params.n_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_q = torch.zeros((test_n_problem, env.params.seqlen)) \n",
    "padded_qa = torch.zeros((test_n_problem, env.params.seqlen))\n",
    "padded_target = torch.full((test_n_problem,env.params.seqlen),-1)\n",
    "padded_pid = torch.zeros((test_n_problem, env.params.seqlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = q.shape[1]\n",
    "padded_q[:, :pred_index]= q\n",
    "padded_qa[:, :pred_index]= qa\n",
    "padded_target[:, :pred_index]= target\n",
    "padded_pid[:, :pred_index]= pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = padded_q.long().to(device)\n",
    "qa = padded_qa.long().to(device)\n",
    "target = padded_target.long().to(device)\n",
    "pid = padded_pid.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss, pred, ct = env.kt_model(q,qa,target,pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopadding_index = np.flatnonzero(padded_target.reshape((-1,)) >= -0.9).tolist()\n",
    "pred_nopadding = pred[nopadding_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pred_nopadding[(pred_index-1)::pred_index]\n",
    "assert test_result.shape == (test_n_problem,)\n",
    "mean_performance = test_result.mean().item()\n",
    "# return mean_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([750])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.418801873922348"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(3).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
